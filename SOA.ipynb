{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9a9285a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Model\n",
    "\n",
    "from transformers import AutoFeatureExtractor, AutoModelForImageClassification\n",
    "\n",
    "extractor = AutoFeatureExtractor.from_pretrained(\"farleyknight-org-username/vit-base-mnist\")\n",
    "\n",
    "model = AutoModelForImageClassification.from_pretrained(\"farleyknight-org-username/vit-base-mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e4311e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTForImageClassification(\n",
       "  (vit): ViTModel(\n",
       "    (embeddings): ViTEmbeddings(\n",
       "      (patch_embeddings): ViTPatchEmbeddings(\n",
       "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): ViTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7d4c4bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Data\n",
    "\n",
    "from Deep_Learning_Term_Paper.Data.Data import DataLoader\n",
    "\n",
    "distortions = ['shot_noise', 'motion_blur']  # desired distortions\n",
    "\n",
    "test_data_obj = DataLoader('test', distortions)\n",
    "\n",
    "# duplicates encoutered in create_dataset function so just using full testing dataset for now\n",
    "\n",
    "'''test_size = 1000\n",
    "\n",
    "#test_ratios = {'clean': 0.2, 'shot_noise': 0.4, 'motion_blur': 0.6}\n",
    "\n",
    "#test_dataset = test_data_obj.create_dataset(test_size, test_ratios)\n",
    "'''\n",
    "\n",
    "test_data_dict = test_data_obj.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dd4a0fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = test_data_dict['clean'][:10]\n",
    "images.extend(test_data_dict['shot_noise'][:10])\n",
    "images.extend(test_data_dict['motion_blur'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "95089ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([28, 28, 1])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# orginal dimensions\n",
    "og_images = images.copy()\n",
    "og_images[0]['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "47d382af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to Pytorch Tensors and appropriate dimensions based on https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "for image in images:\n",
    "    numpy_array = image['image'].numpy() # turn tensorflow tensor to numpy array\n",
    "    \n",
    "    # move channel dimension to the front and convert into Pytorch tensor\n",
    "    tensor = torch.tensor(numpy_array.reshape((1, 28, 28)))\n",
    "    \n",
    "    tensor = tensor.unsqueeze(0) # add batch size dimesion at index 0\n",
    "    \n",
    "    # expand image from 28x28 to 224x244\n",
    "    tensor = F.interpolate(tensor, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "    \n",
    "    # make the tensor have three channels instead of 1\n",
    "    final_tensor = torch.cat((tensor, tensor, tensor), dim=1)\n",
    "    \n",
    "    image['image'] = final_tensor\n",
    "    \n",
    "    # convert label tensorflow tensor to Pytorch tensor\n",
    "    image['label'] = torch.tensor(image['label'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4e555903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new dimensions [batch_size, channels, height, width]\n",
    "images[0]['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fb9ecc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageClassifierOutput(loss=None, logits=tensor([[ 0.3755,  0.3209, -0.1929, -0.2370, -0.0211, -0.4150,  0.2091,  0.1212,\n",
      "         -0.1696, -0.0315]]), hidden_states=None, attentions=None)\n",
      "Predicted Label: 0 Actual Label 2\n",
      "ImageClassifierOutput(loss=None, logits=tensor([[ 0.3573,  0.3987, -0.1424, -0.3290, -0.1062, -0.4989,  0.2738,  0.1245,\n",
      "         -0.1657, -0.0062]]), hidden_states=None, attentions=None)\n",
      "Predicted Label: 1 Actual Label 0\n",
      "ImageClassifierOutput(loss=None, logits=tensor([[ 0.3519,  0.3689, -0.1204, -0.2553, -0.1134, -0.4423,  0.1906,  0.1455,\n",
      "         -0.1682, -0.0480]]), hidden_states=None, attentions=None)\n",
      "Predicted Label: 1 Actual Label 4\n",
      "ImageClassifierOutput(loss=None, logits=tensor([[ 0.3140,  0.3168, -0.2192, -0.2142,  0.0875, -0.2758,  0.1640,  0.1454,\n",
      "         -0.1257, -0.1512]]), hidden_states=None, attentions=None)\n",
      "Predicted Label: 1 Actual Label 8\n",
      "ImageClassifierOutput(loss=None, logits=tensor([[ 0.3576,  0.3348, -0.1841, -0.2325, -0.0402, -0.4236,  0.1924,  0.0955,\n",
      "         -0.1197,  0.0046]]), hidden_states=None, attentions=None)\n",
      "Predicted Label: 0 Actual Label 7\n",
      "ImageClassifierOutput(loss=None, logits=tensor([[ 0.3541,  0.3803, -0.1864, -0.2991, -0.0735, -0.5372,  0.2162,  0.1258,\n",
      "         -0.1384,  0.0185]]), hidden_states=None, attentions=None)\n",
      "Predicted Label: 1 Actual Label 6\n",
      "ImageClassifierOutput(loss=None, logits=tensor([[ 0.3460,  0.3573, -0.1739, -0.2603, -0.1029, -0.4713,  0.2129,  0.1209,\n",
      "         -0.1419, -0.0053]]), hidden_states=None, attentions=None)\n",
      "Predicted Label: 1 Actual Label 0\n",
      "ImageClassifierOutput(loss=None, logits=tensor([[ 0.3279,  0.3351, -0.2092, -0.2083,  0.0676, -0.3624,  0.1752,  0.1237,\n",
      "         -0.1913, -0.0834]]), hidden_states=None, attentions=None)\n",
      "Predicted Label: 1 Actual Label 6\n",
      "ImageClassifierOutput(loss=None, logits=tensor([[ 0.3489,  0.3484, -0.1618, -0.2899, -0.0946, -0.4729,  0.2827,  0.1135,\n",
      "         -0.1690,  0.0051]]), hidden_states=None, attentions=None)\n",
      "Predicted Label: 0 Actual Label 3\n",
      "ImageClassifierOutput(loss=None, logits=tensor([[ 0.2581,  0.3594, -0.1306, -0.1961,  0.0315, -0.4947,  0.1850,  0.1188,\n",
      "         -0.2041, -0.0375]]), hidden_states=None, attentions=None)\n",
      "Predicted Label: 1 Actual Label 1\n",
      "ImageClassifierOutput(loss=None, logits=tensor([[ 0.2554,  0.3378, -0.1491, -0.3173,  0.0717, -0.3437,  0.1143,  0.1691,\n",
      "         -0.0940, -0.1020]]), hidden_states=None, attentions=None)\n",
      "Predicted Label: 1 Actual Label 2\n",
      "ImageClassifierOutput(loss=None, logits=tensor([[ 0.2235,  0.3300, -0.1094, -0.3617,  0.1361, -0.3516,  0.1738,  0.1771,\n",
      "         -0.2209, -0.0782]]), hidden_states=None, attentions=None)\n",
      "Predicted Label: 1 Actual Label 0\n",
      "ImageClassifierOutput(loss=None, logits=tensor([[ 0.3170,  0.3305, -0.0744, -0.2726,  0.0257, -0.4184,  0.1743,  0.1344,\n",
      "         -0.2209, -0.0729]]), hidden_states=None, attentions=None)\n",
      "Predicted Label: 1 Actual Label 4\n",
      "ImageClassifierOutput(loss=None, logits=tensor([[ 0.2719,  0.4255, -0.2031, -0.3395,  0.1118, -0.3209,  0.0851,  0.2247,\n",
      "         -0.0704, -0.0965]]), hidden_states=None, attentions=None)\n",
      "Predicted Label: 1 Actual Label 8\n",
      "ImageClassifierOutput(loss=None, logits=tensor([[ 0.1906,  0.3131, -0.1175, -0.3308,  0.1143, -0.3342,  0.1546,  0.2081,\n",
      "         -0.1226, -0.1121]]), hidden_states=None, attentions=None)\n",
      "Predicted Label: 1 Actual Label 7\n",
      "ImageClassifierOutput(loss=None, logits=tensor([[ 0.2333,  0.3346, -0.1591, -0.3020,  0.0097, -0.3756,  0.1549,  0.1859,\n",
      "         -0.0535, -0.1266]]), hidden_states=None, attentions=None)\n",
      "Predicted Label: 1 Actual Label 6\n",
      "ImageClassifierOutput(loss=None, logits=tensor([[ 0.2518,  0.3555, -0.1152, -0.3460,  0.0652, -0.3947,  0.1697,  0.1555,\n",
      "         -0.1358, -0.0577]]), hidden_states=None, attentions=None)\n",
      "Predicted Label: 1 Actual Label 0\n",
      "ImageClassifierOutput(loss=None, logits=tensor([[ 0.2670,  0.3395, -0.1164, -0.2572,  0.1507, -0.3936,  0.1532,  0.1460,\n",
      "         -0.2616, -0.0786]]), hidden_states=None, attentions=None)\n",
      "Predicted Label: 1 Actual Label 6\n",
      "ImageClassifierOutput(loss=None, logits=tensor([[ 0.3142,  0.3234, -0.1276, -0.3132, -0.0007, -0.4165,  0.1596,  0.1535,\n",
      "         -0.0949, -0.0587]]), hidden_states=None, attentions=None)\n",
      "Predicted Label: 1 Actual Label 3\n",
      "ImageClassifierOutput(loss=None, logits=tensor([[ 0.2397,  0.3956, -0.0868, -0.3591,  0.0675, -0.4088,  0.1109,  0.2103,\n",
      "         -0.0369, -0.1202]]), hidden_states=None, attentions=None)\n",
      "Predicted Label: 1 Actual Label 1\n",
      "ImageClassifierOutput(loss=None, logits=tensor([[ 0.4259,  0.3543, -0.1585, -0.3857, -0.0853, -0.5106,  0.2843,  0.1370,\n",
      "         -0.1802,  0.0733]]), hidden_states=None, attentions=None)\n",
      "Predicted Label: 0 Actual Label 2\n",
      "ImageClassifierOutput(loss=None, logits=tensor([[ 0.4773,  0.4809, -0.0973, -0.4447, -0.1195, -0.5896,  0.3347,  0.1012,\n",
      "         -0.1873,  0.0023]]), hidden_states=None, attentions=None)\n",
      "Predicted Label: 1 Actual Label 0\n",
      "ImageClassifierOutput(loss=None, logits=tensor([[ 0.4807,  0.4701, -0.0631, -0.4141, -0.1186, -0.5894,  0.3205,  0.1554,\n",
      "         -0.1821, -0.0397]]), hidden_states=None, attentions=None)\n",
      "Predicted Label: 0 Actual Label 4\n",
      "ImageClassifierOutput(loss=None, logits=tensor([[ 0.5053,  0.5118, -0.1332, -0.4555, -0.0982, -0.5530,  0.3554,  0.1769,\n",
      "         -0.1635, -0.0479]]), hidden_states=None, attentions=None)\n",
      "Predicted Label: 1 Actual Label 8\n",
      "ImageClassifierOutput(loss=None, logits=tensor([[ 0.4349,  0.3989, -0.1420, -0.3341, -0.0988, -0.4654,  0.2796,  0.1192,\n",
      "         -0.1621,  0.0005]]), hidden_states=None, attentions=None)\n",
      "Predicted Label: 0 Actual Label 7\n",
      "ImageClassifierOutput(loss=None, logits=tensor([[ 0.4404,  0.4498, -0.1421, -0.4400, -0.0904, -0.5659,  0.3212,  0.0890,\n",
      "         -0.1742,  0.0520]]), hidden_states=None, attentions=None)\n",
      "Predicted Label: 1 Actual Label 6\n",
      "ImageClassifierOutput(loss=None, logits=tensor([[ 0.4164,  0.4248, -0.1205, -0.4180, -0.1468, -0.5584,  0.3039,  0.1304,\n",
      "         -0.1629,  0.0259]]), hidden_states=None, attentions=None)\n",
      "Predicted Label: 1 Actual Label 0\n",
      "ImageClassifierOutput(loss=None, logits=tensor([[ 0.4373,  0.4476, -0.1773, -0.3874, -0.1059, -0.4858,  0.3085,  0.1440,\n",
      "         -0.2010,  0.0089]]), hidden_states=None, attentions=None)\n",
      "Predicted Label: 1 Actual Label 6\n",
      "ImageClassifierOutput(loss=None, logits=tensor([[ 0.4374,  0.4061, -0.1003, -0.3927, -0.0496, -0.5620,  0.3439,  0.1048,\n",
      "         -0.1915,  0.0323]]), hidden_states=None, attentions=None)\n",
      "Predicted Label: 0 Actual Label 3\n",
      "ImageClassifierOutput(loss=None, logits=tensor([[ 0.4022,  0.4276, -0.2083, -0.2654, -0.0924, -0.5013,  0.1627,  0.1919,\n",
      "         -0.1590, -0.0373]]), hidden_states=None, attentions=None)\n",
      "Predicted Label: 1 Actual Label 1\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "labels = [x for x in range(10)]\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for image in range(len(images)):\n",
    "        \n",
    "        #pred = model(torch.tensor(og_images[image]['image'].numpy()))\n",
    "        \n",
    "        pred = model(images[image]['image']) \n",
    "        \n",
    "        print(pred)\n",
    "        print('Predicted Label:', labels[pred.logits.argmax(-1).item()], 'Actual Label', images[image]['label'].numpy())\n",
    "        \n",
    "        #test_loss += loss_fn(pred, images[image]['label']).item()\n",
    "        #correct += (pred.argmax(1) == images[image]['label']).type(torch.float).sum().item()\n",
    "    \n",
    "    #print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
